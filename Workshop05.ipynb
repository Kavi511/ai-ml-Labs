{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf468913-b0ab-483c-b052-a10de29d7968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "422a150b-f5e7-425a-ba3f-b2d4293868e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62985942-6157-4864-a744-7e3c24969c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset shape: (8708, 11)\n",
      "\n",
      "Dataset columns: ['id', 'timestamp', 'season', 'holiday', 'workingday', 'weather', 'temp', 'temp_feel', 'humidity', 'windspeed', 'demand']\n",
      "\n",
      "First few rows:\n",
      "   id            timestamp  season holiday workingday                 weather  \\\n",
      "0   1  2017-01-01 00:00:00  spring      No         No  Clear or partly cloudy   \n",
      "1   2  2017-01-01 01:00:00  spring      No         No  Clear or partly cloudy   \n",
      "2   3  2017-01-01 02:00:00  spring      No         No  Clear or partly cloudy   \n",
      "3   4  2017-01-01 03:00:00  spring      No         No  Clear or partly cloudy   \n",
      "4   5  2017-01-01 04:00:00  spring      No         No  Clear or partly cloudy   \n",
      "\n",
      "   temp  temp_feel  humidity  windspeed    demand  \n",
      "0  9.84     14.395      81.0        0.0  2.772589  \n",
      "1  9.02     13.635      80.0        0.0  3.688879  \n",
      "2  9.02     13.635      80.0        0.0  3.465736  \n",
      "3  9.84     14.395      75.0        0.0  2.564949  \n",
      "4  9.84     14.395      75.0        0.0  0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv(\"S:/Course work/3rd year/Artificial Intelligence & Machine Learning/Workshop5/CarSharing.csv\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nDataset columns:\", df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba7eb39-f851-42d9-aaa2-b6495737e8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      "id               0\n",
      "timestamp        0\n",
      "season           0\n",
      "holiday          0\n",
      "workingday       0\n",
      "weather          0\n",
      "temp          1202\n",
      "temp_feel      102\n",
      "humidity        39\n",
      "windspeed      200\n",
      "demand           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d65470b1-43b2-4fa5-9311-00e9c95e87c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Preprocess the data for neural network training\"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Handle datetime if timestamp column exists\n",
    "    if 'timestamp' in df_processed.columns:\n",
    "        try:\n",
    "            df_processed['timestamp'] = pd.to_datetime(df_processed['timestamp'])\n",
    "            df_processed['hour'] = df_processed['timestamp'].dt.hour\n",
    "            df_processed['day_of_week'] = df_processed['timestamp'].dt.dayofweek\n",
    "            df_processed['month'] = df_processed['timestamp'].dt.month\n",
    "            # Drop the original timestamp column\n",
    "            df_processed = df_processed.drop(['timestamp'], axis=1)\n",
    "            print(\"Extracted time features: hour, day_of_week, month\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing timestamp: {e}\")\n",
    "    \n",
    "    # Drop id column if it exists\n",
    "    if 'id' in df_processed.columns:\n",
    "        df_processed = df_processed.drop(['id'], axis=1)\n",
    "        print(\"Dropped 'id' column\")\n",
    "    \n",
    "    # Handle categorical variables\n",
    "    categorical_columns = []\n",
    "    for col in df_processed.columns:\n",
    "        if df_processed[col].dtype == 'object' and col != 'demand':\n",
    "            categorical_columns.append(col)\n",
    "    \n",
    "    print(f\"Categorical columns found: {categorical_columns}\")\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    label_encoders = {}\n",
    "    for column in categorical_columns:\n",
    "        try:\n",
    "            le = LabelEncoder()\n",
    "            df_processed[column] = le.fit_transform(df_processed[column].astype(str))\n",
    "            label_encoders[column] = le\n",
    "            print(f\"Encoded {column}: {list(le.classes_)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error encoding {column}: {e}\")\n",
    "    \n",
    "    # Convert all columns to numeric (except target)\n",
    "    for col in df_processed.columns:\n",
    "        if col != 'demand':\n",
    "            df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
    "    \n",
    "    # Handle missing values\n",
    "    print(\"Handling missing values...\")\n",
    "    numeric_columns = df_processed.select_dtypes(include=[np.number]).columns\n",
    "    df_processed[numeric_columns] = df_processed[numeric_columns].fillna(df_processed[numeric_columns].median())\n",
    "    \n",
    "    print(f\"Final processed shape: {df_processed.shape}\")\n",
    "    return df_processed, label_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ee34ab-5815-4ef6-807a-4600897fd4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing data...\n",
      "Extracted time features: hour, day_of_week, month\n",
      "Dropped 'id' column\n",
      "Categorical columns found: ['season', 'holiday', 'workingday', 'weather']\n",
      "Encoded season: ['fall', 'spring', 'summer', 'winter']\n",
      "Encoded holiday: ['No', 'Yes']\n",
      "Encoded workingday: ['No', 'Yes']\n",
      "Encoded weather: ['Clear or partly cloudy', 'Light snow or rain', 'Mist', 'heavy rain/ice pellets/snow + fog']\n",
      "Handling missing values...\n",
      "Final processed shape: (8708, 12)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "print(\"\\nPreprocessing data...\")\n",
    "df_processed, label_encoders = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a25e183-4f44-439d-b555-124288450bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if demand column exists\n",
    "if 'demand' not in df_processed.columns:\n",
    "    print(\"Error: 'demand' column not found in dataset!\")\n",
    "    print(\"Available columns:\", df_processed.columns.tolist())\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "963f37d2-45fc-4a2d-b6f0-c6bd0ceffbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features shape: (8708, 11)\n",
      "Target shape: (8708,)\n",
      "Feature columns: ['season', 'holiday', 'workingday', 'weather', 'temp', 'temp_feel', 'humidity', 'windspeed', 'hour', 'day_of_week', 'month']\n",
      "\n",
      "Target statistics:\n",
      "Min: 0.0000, Max: 6.7923, Mean: 4.4527, Std: 1.4940\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df_processed.drop('demand', axis=1)\n",
    "y = df_processed['demand']\n",
    "\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature columns: {list(X.columns)}\")\n",
    "\n",
    "# Check for any remaining issues\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(f\"Min: {y.min():.4f}, Max: {y.max():.4f}, Mean: {y.mean():.4f}, Std: {y.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e93a64c-41c7-4ef5-bdde-6e28e57ff740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data...\n",
      "After cleaning - Features shape: (8708, 11), Target shape: (8708,)\n"
     ]
    }
   ],
   "source": [
    "# Remove any rows with infinite or NaN values\n",
    "print(\"Cleaning data...\")\n",
    "mask = np.isfinite(X).all(axis=1) & np.isfinite(y)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "print(f\"After cleaning - Features shape: {X.shape}, Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "432088dd-432f-442e-829a-ae6fa98d3f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling features...\n",
      "Scaled features shape: (8708, 11)\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "print(\"Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Check for NaN in scaled features\n",
    "if np.isnan(X_scaled).any():\n",
    "    print(\"Warning: NaN found in scaled features. Replacing with zeros.\")\n",
    "    X_scaled = np.nan_to_num(X_scaled, nan=0.0)\n",
    "\n",
    "print(f\"Scaled features shape: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84cc7daa-9a16-4ca7-a684-b1fe8fa4cf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network architecture\n",
    "def create_model(input_dim, hidden_layers=3, neurons_per_layer=64, dropout_rate=0.2, learning_rate=0.001):\n",
    "    \"\"\"Create a deep neural network model\"\"\"\n",
    "    # Clear any existing models\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Input layer with regularization\n",
    "    model.add(layers.Dense(neurons_per_layer, \n",
    "                          activation='relu', \n",
    "                          input_shape=(input_dim,),\n",
    "                          kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    # Hidden layers\n",
    "    for i in range(hidden_layers - 1):\n",
    "        model.add(layers.Dense(neurons_per_layer, \n",
    "                              activation='relu',\n",
    "                              kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e49dbeab-40ad-4d74-8794-34c829ec712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate all regression evaluation metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate comprehensive regression metrics with NaN handling\"\"\"\n",
    "    # Convert to numpy arrays and ensure they're 1D\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_pred = np.array(y_pred).flatten()\n",
    "    \n",
    "    # Remove NaN and infinite values\n",
    "    mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    if np.sum(mask) == 0:\n",
    "        return {\n",
    "            'MSE': np.inf,\n",
    "            'RMSE': np.inf,\n",
    "            'MAE': np.inf,\n",
    "            'R2': -np.inf,\n",
    "            'MAPE': np.inf,\n",
    "            'MBE': np.inf\n",
    "        }\n",
    "    \n",
    "    y_true_clean = y_true[mask]\n",
    "    y_pred_clean = y_pred[mask]\n",
    "    \n",
    "    try:\n",
    "        mse = mean_squared_error(y_true_clean, y_pred_clean)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_true_clean, y_pred_clean)\n",
    "        r2 = r2_score(y_true_clean, y_pred_clean)\n",
    "        \n",
    "        # Mean Absolute Percentage Error (MAPE) - handle division by zero\n",
    "        mask_nonzero = y_true_clean != 0\n",
    "        if np.sum(mask_nonzero) > 0:\n",
    "            mape = np.mean(np.abs((y_true_clean[mask_nonzero] - y_pred_clean[mask_nonzero]) / y_true_clean[mask_nonzero])) * 100\n",
    "        else:\n",
    "            mape = 0\n",
    "        \n",
    "        # Mean Bias Error (MBE)\n",
    "        mbe = np.mean(y_pred_clean - y_true_clean)\n",
    "        \n",
    "        return {\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R2': r2,\n",
    "            'MAPE': mape,\n",
    "            'MBE': mbe\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating metrics: {e}\")\n",
    "        return {\n",
    "            'MSE': np.inf,\n",
    "            'RMSE': np.inf,\n",
    "            'MAE': np.inf,\n",
    "            'R2': -np.inf,\n",
    "            'MAPE': np.inf,\n",
    "            'MBE': np.inf\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fa31de3-d59d-4682-a326-fb528c69e918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter combinations to test\n",
    "param_combinations = [\n",
    "    {'hidden_layers': 2, 'neurons_per_layer': 32, 'dropout_rate': 0.1, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 50},\n",
    "    {'hidden_layers': 2, 'neurons_per_layer': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'batch_size': 64, 'epochs': 50},\n",
    "    {'hidden_layers': 3, 'neurons_per_layer': 32, 'dropout_rate': 0.1, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 50},\n",
    "    {'hidden_layers': 3, 'neurons_per_layer': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'batch_size': 64, 'epochs': 50},\n",
    "    {'hidden_layers': 3, 'neurons_per_layer': 64, 'dropout_rate': 0.3, 'learning_rate': 0.0001, 'batch_size': 64, 'epochs': 75},\n",
    "    {'hidden_layers': 4, 'neurons_per_layer': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'batch_size': 64, 'epochs': 50},\n",
    "    {'hidden_layers': 2, 'neurons_per_layer': 128, 'dropout_rate': 0.2, 'learning_rate': 0.0001, 'batch_size': 32, 'epochs': 75},\n",
    "    {'hidden_layers': 3, 'neurons_per_layer': 128, 'dropout_rate': 0.1, 'learning_rate': 0.001, 'batch_size': 128, 'epochs': 50}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee964dca-aa96-4414-ad90-640a4b5a747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with 5-fold cross-validation\n",
    "def hyperparameter_tuning(X, y, param_combinations):\n",
    "    \"\"\"Perform hyperparameter tuning using cross-validation\"\"\"\n",
    "    \n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "    best_metrics = None\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    print(f\"Testing {len(param_combinations)} parameter combinations with 5-fold CV...\")\n",
    "    \n",
    "    for i, params in enumerate(param_combinations):\n",
    "        print(f\"\\nTrial {i+1}/{len(param_combinations)}: {params}\")\n",
    "        \n",
    "        fold_scores = []\n",
    "        fold_metrics = {'MSE': [], 'RMSE': [], 'MAE': [], 'R2': [], 'MAPE': [], 'MBE': []}\n",
    "        \n",
    "        for fold_num, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "            try:\n",
    "                X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "                y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "                \n",
    "                # Create and train model\n",
    "                model = create_model(\n",
    "                    input_dim=X.shape[1],\n",
    "                    hidden_layers=params['hidden_layers'],\n",
    "                    neurons_per_layer=params['neurons_per_layer'],\n",
    "                    dropout_rate=params['dropout_rate'],\n",
    "                    learning_rate=params['learning_rate']\n",
    "                )\n",
    "                \n",
    "                # Callbacks\n",
    "                early_stopping = keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss', \n",
    "                    patience=10, \n",
    "                    restore_best_weights=True, \n",
    "                    verbose=0,\n",
    "                    min_delta=0.001\n",
    "                )\n",
    "                \n",
    "                reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "                    monitor='val_loss', \n",
    "                    factor=0.5, \n",
    "                    patience=5, \n",
    "                    min_lr=1e-7,\n",
    "                    verbose=0\n",
    "                )\n",
    "                \n",
    "                # Train the model\n",
    "                history = model.fit(\n",
    "                    X_train_fold, y_train_fold,\n",
    "                    validation_data=(X_val_fold, y_val_fold),\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0,\n",
    "                    callbacks=[early_stopping, reduce_lr]\n",
    "                )\n",
    "                \n",
    "                # Predict and calculate metrics\n",
    "                y_pred = model.predict(X_val_fold, verbose=0).flatten()\n",
    "                \n",
    "                # Check for NaN in predictions\n",
    "                if np.isnan(y_pred).any():\n",
    "                    print(f\"Warning: NaN predictions found in fold {fold_num}\")\n",
    "                    y_pred = np.nan_to_num(y_pred, nan=np.median(y_train_fold))\n",
    "                \n",
    "                metrics = calculate_metrics(y_val_fold, y_pred)\n",
    "                \n",
    "                if np.isfinite(metrics['MSE']):\n",
    "                    fold_scores.append(metrics['MSE'])\n",
    "                    for metric_name, value in metrics.items():\n",
    "                        fold_metrics[metric_name].append(value)\n",
    "                else:\n",
    "                    print(f\"Invalid metrics in fold {fold_num}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error in fold {fold_num}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if len(fold_scores) >= 3:  # Need at least 3 valid folds\n",
    "            # Calculate average metrics across folds\n",
    "            avg_score = np.mean(fold_scores)\n",
    "            avg_metrics = {metric: np.mean(values) for metric, values in fold_metrics.items() if len(values) > 0}\n",
    "            \n",
    "            print(f\"Valid folds: {len(fold_scores)}/5\")\n",
    "            print(f\"Average MSE: {avg_score:.4f}\")\n",
    "            if 'R2' in avg_metrics:\n",
    "                print(f\"Average R2: {avg_metrics['R2']:.4f}\")\n",
    "            \n",
    "            # Update best parameters if this is the best score so far\n",
    "            if avg_score < best_score:\n",
    "                best_score = avg_score\n",
    "                best_params = params\n",
    "                best_metrics = avg_metrics\n",
    "                print(\"*** New best parameters found! ***\")\n",
    "        else:\n",
    "            print(f\"Not enough valid folds ({len(fold_scores)}/5) for this parameter combination.\")\n",
    "    \n",
    "    return best_params, best_score, best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd682e78-c14a-472a-bf2f-69114da6a90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning...\n",
      "Testing 8 parameter combinations with 5-fold CV...\n",
      "\n",
      "Trial 1/8: {'hidden_layers': 2, 'neurons_per_layer': 32, 'dropout_rate': 0.1, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 50}\n",
      "WARNING:tensorflow:From C:\\Users\\Kavishka Herath\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Valid folds: 5/5\n",
      "Average MSE: 0.2463\n",
      "Average R2: 0.8897\n",
      "*** New best parameters found! ***\n",
      "\n",
      "Trial 2/8: {'hidden_layers': 2, 'neurons_per_layer': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'batch_size': 64, 'epochs': 50}\n",
      "Valid folds: 5/5\n",
      "Average MSE: 0.2332\n",
      "Average R2: 0.8955\n",
      "*** New best parameters found! ***\n",
      "\n",
      "Trial 3/8: {'hidden_layers': 3, 'neurons_per_layer': 32, 'dropout_rate': 0.1, 'learning_rate': 0.001, 'batch_size': 32, 'epochs': 50}\n",
      "Valid folds: 5/5\n",
      "Average MSE: 0.2302\n",
      "Average R2: 0.8969\n",
      "*** New best parameters found! ***\n",
      "\n",
      "Trial 4/8: {'hidden_layers': 3, 'neurons_per_layer': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'batch_size': 64, 'epochs': 50}\n",
      "Valid folds: 5/5\n",
      "Average MSE: 0.2266\n",
      "Average R2: 0.8983\n",
      "*** New best parameters found! ***\n",
      "\n",
      "Trial 5/8: {'hidden_layers': 3, 'neurons_per_layer': 64, 'dropout_rate': 0.3, 'learning_rate': 0.0001, 'batch_size': 64, 'epochs': 75}\n",
      "Valid folds: 5/5\n",
      "Average MSE: 0.7068\n",
      "Average R2: 0.6831\n",
      "\n",
      "Trial 6/8: {'hidden_layers': 4, 'neurons_per_layer': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'batch_size': 64, 'epochs': 50}\n",
      "Valid folds: 5/5\n",
      "Average MSE: 0.3053\n",
      "Average R2: 0.8631\n",
      "\n",
      "Trial 7/8: {'hidden_layers': 2, 'neurons_per_layer': 128, 'dropout_rate': 0.2, 'learning_rate': 0.0001, 'batch_size': 32, 'epochs': 75}\n",
      "Valid folds: 5/5\n",
      "Average MSE: 0.4057\n",
      "Average R2: 0.8186\n",
      "\n",
      "Trial 8/8: {'hidden_layers': 3, 'neurons_per_layer': 128, 'dropout_rate': 0.1, 'learning_rate': 0.001, 'batch_size': 128, 'epochs': 50}\n",
      "Valid folds: 5/5\n",
      "Average MSE: 0.1976\n",
      "Average R2: 0.9114\n",
      "*** New best parameters found! ***\n",
      "\n",
      "==================================================\n",
      "HYPERPARAMETER TUNING RESULTS\n",
      "==================================================\n",
      "Best parameters: {'hidden_layers': 3, 'neurons_per_layer': 128, 'dropout_rate': 0.1, 'learning_rate': 0.001, 'batch_size': 128, 'epochs': 50}\n",
      "Best MSE score: 0.1976\n",
      "\n",
      "Best model performance metrics:\n",
      "MSE: 0.1976\n",
      "RMSE: 0.4444\n",
      "MAE: 0.3303\n",
      "R2: 0.9114\n",
      "MAPE: 10.3122\n",
      "MBE: 0.0371\n"
     ]
    }
   ],
   "source": [
    "# Perform hyperparameter tuning\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "best_params, best_score, best_metrics = hyperparameter_tuning(X_scaled, y, param_combinations)\n",
    "\n",
    "if best_params is None:\n",
    "    print(\"Error: No valid parameter combination found!\")\n",
    "    # Use default parameters\n",
    "    best_params = {'hidden_layers': 3, 'neurons_per_layer': 64, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'batch_size': 64, 'epochs': 50}\n",
    "    print(f\"Using default parameters: {best_params}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"HYPERPARAMETER TUNING RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "if best_metrics:\n",
    "    print(f\"Best MSE score: {best_score:.4f}\")\n",
    "    print(\"\\nBest model performance metrics:\")\n",
    "    for metric_name, value in best_metrics.items():\n",
    "        print(f\"{metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce790529-096d-4548-b881-99398a164cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FINAL MODEL EVALUATION WITH 5-FOLD CROSS-VALIDATION\n",
      "==================================================\n",
      "\n",
      "Fold 1/5:\n",
      "MSE: 0.2098\n",
      "RMSE: 0.4581\n",
      "MAE: 0.3414\n",
      "R2: 0.9044\n",
      "MAPE: 10.4595%\n",
      "MBE: 0.0983\n",
      "\n",
      "Fold 2/5:\n",
      "MSE: 0.2064\n",
      "RMSE: 0.4543\n",
      "MAE: 0.3436\n",
      "R2: 0.9103\n",
      "MAPE: 10.4257%\n",
      "MBE: -0.0103\n",
      "\n",
      "Fold 3/5:\n",
      "MSE: 0.1865\n",
      "RMSE: 0.4319\n",
      "MAE: 0.3200\n",
      "R2: 0.9172\n",
      "MAPE: 10.1050%\n",
      "MBE: 0.0023\n",
      "\n",
      "Fold 4/5:\n",
      "MSE: 0.1848\n",
      "RMSE: 0.4298\n",
      "MAE: 0.3261\n",
      "R2: 0.9141\n",
      "MAPE: 9.4727%\n",
      "MBE: 0.0188\n",
      "\n",
      "Fold 5/5:\n",
      "MSE: 0.2007\n",
      "RMSE: 0.4480\n",
      "MAE: 0.3278\n",
      "R2: 0.9108\n",
      "MAPE: 10.7693%\n",
      "MBE: 0.0490\n"
     ]
    }
   ],
   "source": [
    "# Train the final model with best parameters using 5-fold cross-validation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL MODEL EVALUATION WITH 5-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled)):\n",
    "    print(f\"\\nFold {fold + 1}/5:\")\n",
    "    \n",
    "    try:\n",
    "        X_train_fold, X_val_fold = X_scaled[train_idx], X_scaled[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Create and train the best model\n",
    "        model = create_model(\n",
    "            input_dim=X_scaled.shape[1],\n",
    "            hidden_layers=best_params['hidden_layers'],\n",
    "            neurons_per_layer=best_params['neurons_per_layer'],\n",
    "            dropout_rate=best_params['dropout_rate'],\n",
    "            learning_rate=best_params['learning_rate']\n",
    "        )\n",
    "        \n",
    "        # Callbacks\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=15, restore_best_weights=True, verbose=0\n",
    "        )\n",
    "        \n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7, verbose=0\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            validation_data=(X_val_fold, y_val_fold),\n",
    "            epochs=best_params['epochs'],\n",
    "            batch_size=best_params['batch_size'],\n",
    "            verbose=0,\n",
    "            callbacks=[early_stopping, reduce_lr]\n",
    "        )\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_val_fold, verbose=0).flatten()\n",
    "        \n",
    "        # Handle NaN predictions\n",
    "        if np.isnan(y_pred).any():\n",
    "            print(\"Warning: NaN predictions found, replacing with median\")\n",
    "            y_pred = np.nan_to_num(y_pred, nan=np.median(y_train_fold))\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_metrics(y_val_fold, y_pred)\n",
    "        \n",
    "        if np.isfinite(metrics['MSE']):\n",
    "            fold_results.append(metrics)\n",
    "            \n",
    "            print(f\"MSE: {metrics['MSE']:.4f}\")\n",
    "            print(f\"RMSE: {metrics['RMSE']:.4f}\")\n",
    "            print(f\"MAE: {metrics['MAE']:.4f}\")\n",
    "            print(f\"R2: {metrics['R2']:.4f}\")\n",
    "            print(f\"MAPE: {metrics['MAPE']:.4f}%\")\n",
    "            print(f\"MBE: {metrics['MBE']:.4f}\")\n",
    "        else:\n",
    "            print(\"Invalid metrics for this fold\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in fold {fold + 1}: {e}\")\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65168ab8-fcff-484c-aa71-a39c5ba43172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FINAL RESULTS - 5-FOLD CROSS-VALIDATION SUMMARY\n",
      "==================================================\n",
      "\n",
      "MSE:\n",
      "  Mean: 0.1976 ± 0.0102\n",
      "  Range: [0.1848, 0.2098]\n",
      "\n",
      "RMSE:\n",
      "  Mean: 0.4444 ± 0.0115\n",
      "  Range: [0.4298, 0.4581]\n",
      "\n",
      "MAE:\n",
      "  Mean: 0.3318 ± 0.0091\n",
      "  Range: [0.3200, 0.3436]\n",
      "\n",
      "R2:\n",
      "  Mean: 0.9114 ± 0.0043\n",
      "  Range: [0.9044, 0.9172]\n",
      "\n",
      "MAPE:\n",
      "  Mean: 10.2464 ± 0.4404\n",
      "  Range: [9.4727, 10.7693]\n",
      "\n",
      "MBE:\n",
      "  Mean: 0.0316 ± 0.0388\n",
      "  Range: [-0.0103, 0.0983]\n",
      "\n",
      "==================================================\n",
      "TRAINING FINAL MODEL ON FULL DATASET\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - loss: 20.5178 - mae: 4.2333 - val_loss: 14.3952 - val_mae: 3.5341 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 12.0912 - mae: 3.2087 - val_loss: 5.5204 - val_mae: 2.0834 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.3195 - mae: 1.6961 - val_loss: 1.3478 - val_mae: 0.7943 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.0687 - mae: 1.0301 - val_loss: 1.1207 - val_mae: 0.6859 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.7880 - mae: 0.9486 - val_loss: 1.0238 - val_mae: 0.6575 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.6374 - mae: 0.9025 - val_loss: 0.9196 - val_mae: 0.6070 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.4112 - mae: 0.8303 - val_loss: 0.8289 - val_mae: 0.5575 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.3486 - mae: 0.7959 - val_loss: 0.8115 - val_mae: 0.5633 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1842 - mae: 0.7434 - val_loss: 0.7160 - val_mae: 0.5060 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.1107 - mae: 0.7113 - val_loss: 0.7245 - val_mae: 0.5142 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0809 - mae: 0.6983 - val_loss: 0.6607 - val_mae: 0.4781 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1.0053 - mae: 0.6624 - val_loss: 0.6166 - val_mae: 0.4610 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.9924 - mae: 0.6578 - val_loss: 0.5895 - val_mae: 0.4373 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.9270 - mae: 0.6306 - val_loss: 0.5713 - val_mae: 0.4275 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.8851 - mae: 0.6129 - val_loss: 0.5340 - val_mae: 0.4032 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.8451 - mae: 0.5956 - val_loss: 0.5215 - val_mae: 0.3945 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.8438 - mae: 0.5963 - val_loss: 0.5226 - val_mae: 0.4012 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.8051 - mae: 0.5812 - val_loss: 0.5284 - val_mae: 0.4050 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.8161 - mae: 0.5863 - val_loss: 0.5263 - val_mae: 0.4103 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.7650 - mae: 0.5660 - val_loss: 0.4901 - val_mae: 0.3841 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.7385 - mae: 0.5495 - val_loss: 0.4976 - val_mae: 0.3890 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.7207 - mae: 0.5462 - val_loss: 0.5288 - val_mae: 0.4251 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.7139 - mae: 0.5407 - val_loss: 0.4782 - val_mae: 0.3863 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.6837 - mae: 0.5301 - val_loss: 0.4832 - val_mae: 0.4007 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.6807 - mae: 0.5325 - val_loss: 0.4679 - val_mae: 0.3858 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.6585 - mae: 0.5187 - val_loss: 0.4526 - val_mae: 0.3734 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.6434 - mae: 0.5106 - val_loss: 0.4473 - val_mae: 0.3718 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.6121 - mae: 0.4956 - val_loss: 0.4484 - val_mae: 0.3796 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.6094 - mae: 0.4985 - val_loss: 0.4309 - val_mae: 0.3718 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.5954 - mae: 0.4908 - val_loss: 0.4410 - val_mae: 0.3757 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.6024 - mae: 0.4965 - val_loss: 0.4266 - val_mae: 0.3707 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.5819 - mae: 0.4864 - val_loss: 0.4399 - val_mae: 0.3828 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.5792 - mae: 0.4866 - val_loss: 0.4062 - val_mae: 0.3649 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.5804 - mae: 0.4955 - val_loss: 0.4060 - val_mae: 0.3612 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5516 - mae: 0.4793 - val_loss: 0.4178 - val_mae: 0.3732 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.5521 - mae: 0.4755 - val_loss: 0.4164 - val_mae: 0.3782 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.5420 - mae: 0.4745 - val_loss: 0.3797 - val_mae: 0.3529 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.5254 - mae: 0.4711 - val_loss: 0.3789 - val_mae: 0.3540 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5147 - mae: 0.4639 - val_loss: 0.3797 - val_mae: 0.3585 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.5175 - mae: 0.4647 - val_loss: 0.3878 - val_mae: 0.3665 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.4876 - mae: 0.4522 - val_loss: 0.3792 - val_mae: 0.3607 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.4887 - mae: 0.4524 - val_loss: 0.3673 - val_mae: 0.3557 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.4660 - mae: 0.4427 - val_loss: 0.3522 - val_mae: 0.3497 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.4789 - mae: 0.4551 - val_loss: 0.3567 - val_mae: 0.3519 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.4727 - mae: 0.4517 - val_loss: 0.3532 - val_mae: 0.3536 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.4679 - mae: 0.4467 - val_loss: 0.3746 - val_mae: 0.3700 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.4576 - mae: 0.4434 - val_loss: 0.3454 - val_mae: 0.3515 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.4611 - mae: 0.4449 - val_loss: 0.3431 - val_mae: 0.3535 - learning_rate: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.4615 - mae: 0.4468 - val_loss: 0.3407 - val_mae: 0.3573 - learning_rate: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.4382 - mae: 0.4357 - val_loss: 0.3243 - val_mae: 0.3437 - learning_rate: 0.0010\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\n",
      "Final Model Test Set Performance:\n",
      "MSE: 0.2070\n",
      "RMSE: 0.4550\n",
      "MAE: 0.3437\n",
      "R2: 0.9056\n",
      "MAPE: 10.3165\n",
      "MBE: -0.0311\n",
      "\n",
      "==================================================\n",
      "MODEL SUMMARY\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m1,536\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">107,141</span> (418.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m107,141\u001b[0m (418.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,457</span> (138.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,457\u001b[0m (138.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,916</span> (277.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m70,916\u001b[0m (277.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature names used in the model:\n",
      "0: season\n",
      "1: holiday\n",
      "2: workingday\n",
      "3: weather\n",
      "4: temp\n",
      "5: temp_feel\n",
      "6: humidity\n",
      "7: windspeed\n",
      "8: hour\n",
      "9: day_of_week\n",
      "10: month\n",
      "\n",
      "Dataset size: 8708 samples\n",
      "Number of features: 11\n",
      "Target range: [0.0000, 6.7923]\n"
     ]
    }
   ],
   "source": [
    "# Calculate final statistics across all folds\n",
    "if len(fold_results) > 0:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL RESULTS - 5-FOLD CROSS-VALIDATION SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    final_metrics = {}\n",
    "    for metric_name in fold_results[0].keys():\n",
    "        values = [fold[metric_name] for fold in fold_results]\n",
    "        final_metrics[metric_name] = {\n",
    "            'mean': np.mean(values),\n",
    "            'std': np.std(values),\n",
    "            'min': np.min(values),\n",
    "            'max': np.max(values)\n",
    "        }\n",
    "\n",
    "    for metric_name, stats in final_metrics.items():\n",
    "        print(f\"\\n{metric_name}:\")\n",
    "        print(f\"  Mean: {stats['mean']:.4f} ± {stats['std']:.4f}\")\n",
    "        print(f\"  Range: [{stats['min']:.4f}, {stats['max']:.4f}]\")\n",
    "\n",
    "    # Train final model on full dataset\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"TRAINING FINAL MODEL ON FULL DATASET\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Split data for final training (80-20 split)\n",
    "    X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    final_model = create_model(\n",
    "        input_dim=X_scaled.shape[1],\n",
    "        hidden_layers=best_params['hidden_layers'],\n",
    "        neurons_per_layer=best_params['neurons_per_layer'],\n",
    "        dropout_rate=best_params['dropout_rate'],\n",
    "        learning_rate=best_params['learning_rate']\n",
    "    )\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=15, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=7, min_lr=1e-7\n",
    "    )\n",
    "\n",
    "    final_history = final_model.fit(\n",
    "        X_train_final, y_train_final,\n",
    "        validation_data=(X_test_final, y_test_final),\n",
    "        epochs=best_params['epochs'],\n",
    "        batch_size=best_params['batch_size'],\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Final predictions and evaluation\n",
    "    y_pred_final = final_model.predict(X_test_final).flatten()\n",
    "    \n",
    "    # Handle NaN predictions\n",
    "    if np.isnan(y_pred_final).any():\n",
    "        print(\"Warning: NaN predictions in final model, replacing with median\")\n",
    "        y_pred_final = np.nan_to_num(y_pred_final, nan=np.median(y_train_final))\n",
    "    \n",
    "    final_test_metrics = calculate_metrics(y_test_final, y_pred_final)\n",
    "\n",
    "    print(f\"\\nFinal Model Test Set Performance:\")\n",
    "    for metric_name, value in final_test_metrics.items():\n",
    "        print(f\"{metric_name}: {value:.4f}\")\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"MODEL SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    final_model.summary()\n",
    "\n",
    "    print(f\"\\nFeature names used in the model:\")\n",
    "    for i, feature in enumerate(X.columns):\n",
    "        print(f\"{i}: {feature}\")\n",
    "        \n",
    "    print(f\"\\nDataset size: {X_scaled.shape[0]} samples\")\n",
    "    print(f\"Number of features: {X_scaled.shape[1]}\")\n",
    "    print(f\"Target range: [{y.min():.4f}, {y.max():.4f}]\")\n",
    "else:\n",
    "    print(\"No valid fold results obtained. Please check your data and parameters.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4610eb2-778d-4cb6-b950-81de03fcd6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Features:\n",
    "\n",
    "# Data Preprocessing:\n",
    "# - Extracts time features from timestamp (hour, day_of_week, month)\n",
    "# - Encodes categorical variables (season, holiday, workingday, weather)\n",
    "# - Standardizes features for neural network training\n",
    "\n",
    "\n",
    "# Neural Network Architecture:\n",
    "# - Configurable deep network with multiple hidden layers\n",
    "# - Dropout layers for regularization\n",
    "# - Adam optimizer with configurable learning rate\n",
    "\n",
    "\n",
    "# - Hyperparameter Tuning:\n",
    "# - Grid search over multiple hyperparameters\n",
    "# - 5-fold cross-validation for each parameter combination\n",
    "# - Early stopping to prevent overfitting\n",
    "\n",
    "# Comprehensive Evaluation Metrics:\n",
    "# - MSE (Mean Squared Error)\n",
    "# - RMSE (Root Mean Squared Error)\n",
    "# - MAE (Mean Absolute Error)\n",
    "# - R² (R-squared)\n",
    "# - MAPE (Mean Absolute Percentage Error)\n",
    "# - MBE (Mean Bias Error)\n",
    "\n",
    "# 5-Fold Cross-Validation:\n",
    "# - Evaluates model performance across different data splits\n",
    "# - Provides statistical summary (mean, std, min, max) for all metrics\n",
    "\n",
    "# Final Model Training:\n",
    "# - Trains the best model on the full dataset\n",
    "# - Provides final test set evaluation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
